# doc2vec-api

The repository contains some corpus(Korean), python scripts for training and inferring test document vectors using doc2vec.


Raw Corpus
==========================
* [Korean Wikipedia / space tokenizer (467MB)](https://drive.google.com/open?id=0B38stK5a3ByqZWRxS2lWMkhqQ2c)
* [Korean Wikipedia / mecab pos tokenizer / tag info (910MB)](https://drive.google.com/open?id=0B38stK5a3ByqcGhuUE93YnIxN0U)
* [Korean Wikipedia / mecab pos tokenizer / no tag info (535MB)](https://drive.google.com/open?id=0B38stK5a3ByqQWtBZ1pQWjFvWlU)




